---
layout: default 
title: "907 - As a Solutions Architect for a multinati"
link: "https://www.exam-answer.com/amazon/SAA-C03/question124"
keywords: kinesis, EMR, mining, RedShift, AI, ML, RDS
---


[.question]
== 907-64a1fa61f053625db51dde6d.


****

[.query]
--
Here's the architectural headache you've been given:

- A government office with tens of thousands of employees and growing
- Offices throughout every state in the uniion
- Sensors on every door, door, entryway and turn stile that logs a user's transit
- JSON data from every card swipe or sensor trip is pushed to AWS
- Realtime analytics on the ingested data must be constantly performed
- Data must be processed in parallel to keep up with the throughput
- Data analysis results must be durable, reliable and stored persistently
- Stored data is constantly data mined
- The whole system must be able to scale as new deparments are brought online

What's the simplest architecture that will solve your headache?

--

[.list]
--
* [ ] A. Use Amazon Kinesis Streams and save the results to S3 for distributed storage.
* [ ] B. Use Amazon Kinesis Streams to handle incoming data and then integrate with Kinesis Data Analytics along with RedShift and AWS Elastic MapReduce.
* [ ] C. Use SQS to receive the data coming from sensors. Write a custom Python app to mine the data and store the results in S3.
* [ ] D. Use Amazon Kinesis Streams to ingest data, a custom Python app to process the data and persist to an AWS managed RDS and AWS Elastic MapReduce to mine the data.

--
****

[.answer]
Correct Answer  B

[.explanation]
--
This is a complicated problem with many possible solutions, but the best solution is to use Amazon Kinesis Streams with Kinesis Data Analytics along with RedShift and AWS EMR

The solution described here, which involves using Amazon Kinesis Streams, Custom Kinesis Streams Applications, AWS EMR (Elastic MapReduce), and RedShift, is a powerful and efficient way to handle streaming data from multiple clients who send JSON data to a server. Here's why it is considered a durable and reliable solution on AWS:

Scalability and Durability: Amazon Kinesis Streams is designed to handle large-scale streaming data with high throughput and low latency. It can easily accommodate the data coming from many clients, ensuring scalability as the number of clients and data volume increases. Additionally, Kinesis Streams provides built-in fault tolerance and durability, ensuring that the data is reliably stored and available for processing.

Data Ingestion: Amazon Kinesis Streams acts as the ingestion layer for the streaming data. It allows you to easily capture and ingest the JSON data sent by the clients. Kinesis Streams can handle a high rate of data ingestion and buffer the data until it is processed, ensuring that no data is lost during peak traffic or when the processing infrastructure is busy.

Real-time Data Processing: Custom Kinesis Streams Applications, also known as Kinesis Data Analytics, enable you to perform real-time analysis and processing of the streaming data. With Kinesis Data Analytics, you can write SQL-like queries or use pre-built functions to filter, transform, aggregate, and analyze the JSON data as it arrives. This allows you to derive valuable insights and actionable outcomes from the streaming data in real-time.

Big Data Analytics: AWS EMR, which stands for Elastic MapReduce, is a managed service for big data processing. By integrating EMR into the solution, you can perform advanced analytics on the processed data from Kinesis Streams Applications. EMR supports various big data processing frameworks such as Apache Spark and Apache Hadoop, enabling you to run complex analytics jobs, machine learning algorithms, or custom data processing tasks on the data.

Data Warehousing: RedShift is a fully managed data warehousing service provided by AWS. By moving the analytics outcomes from Kinesis Streams Applications and EMR to RedShift, you can store the processed data in a structured, query-optimized format. RedShift allows for efficient querying and analysis of large volumes of data, making it suitable for storing and analyzing the results of your streaming data analysis.

Integration and Data Pipeline: The combination of Amazon Kinesis Streams, Custom Kinesis Streams Applications, AWS EMR, and RedShift creates an end-to-end data pipeline for handling streaming data. It enables seamless integration between the different services, allowing you to ingest, process, analyze, and store the data efficiently. You can also integrate other AWS services or custom applications into the pipeline as per your specific requirements.

Overall, this solution leverages the strengths of Amazon Kinesis Streams, real-time data processing with Kinesis Data Analytics, advanced analytics with EMR, and data warehousing with RedShift to provide a scalable, real-time, and analytics-driven approach for handling streaming data from multiple clients.

One of the places people trip up on this question is in the use of RDS vs RedShift for storing results. Always make sure you know the different use cases for RDS vs RedShift. 

=== RedShift vs RDS

RedShift and RDS (Relational Database Service) are two different AWS database services that serve distinct purposes. Here's a comparison of RedShift and RDS:

==== Database Type:

RedShift: It is a fully managed data warehousing solution designed for handling large volumes of structured data and performing complex analytics queries. RedShift is optimized for online analytical processing (OLAP) workloads.
RDS: It is a managed relational database service that supports various database engines, including Amazon Aurora, MySQL, PostgreSQL, Oracle Database, and Microsoft SQL Server. RDS is suitable for traditional online transaction processing (OLTP) workloads.

==== Purpose:

RedShift: It is primarily used for data warehousing and business intelligence (BI) scenarios where large datasets are stored and analyzed. RedShift provides high-performance analytics capabilities, columnar storage, and parallel query execution.
RDS: It is used for traditional database applications that require efficient data storage, retrieval, and transactional processing. RDS offers features like automated backups, automatic software patching, and scalability for relational databases.

==== Data Volume and Scale:

RedShift: It is designed to handle massive amounts of data and can scale to petabyte-scale data warehouses. RedShift uses a columnar storage format and parallel processing to achieve high performance on large datasets.
RDS: It can handle moderate to large-sized databases, but it has limitations compared to RedShift in terms of scaling to extremely large volumes of data.

==== Performance and Analytics:

RedShift: It is optimized for running complex analytical queries across large datasets. RedShift's columnar storage, data compression, and parallel execution enable faster query performance for analytical workloads.
RDS: It is designed for transactional workloads and offers good performance for OLTP applications that require frequent data inserts, updates, and deletes. However, it may not be as performant as RedShift for complex analytics queries.

==== Pricing Model:

RedShift: It has a different pricing model compared to RDS. RedShift pricing is based on the number of nodes in the cluster, data transfer, and storage usage.
RDS: It has a pricing model based on the database instance type, storage capacity, and data transfer. The pricing structure for RDS varies depending on the chosen database engine.

RedShift is purpose-built for data warehousing and analytics workloads, providing high-performance query capabilities on large datasets. RDS, on the other hand, is a managed relational database service suitable for traditional OLTP workloads. The choice between RedShift and RDS depends on your specific use case, data volume, performance requirements, and the type of database workload you need to support.

If the scenario requires a transactional database, RDS is normally the right choice. If the scenario requires parallel processing of large data sets for the use of data mining, AI or ML, then go with RDS.


--

[.ka]
null

'''


